
hdfs.host=ytddatademo
hdfs.port=8020
hdfs.username=hdfs
hdfs.password=hdfs
hdfs.rootpath=/di/

hdfs.kerberos.flag= false
hdfs.kerberos.conf= /etc/krb5.conf
hdfs.kerberos.realm= HADOOP.COM
hdfs.kerberos.kdc= 192.168.2.131
hdfs.kerberos.nameNodeprincipal= nn/ytddata0.localdomain@HADOOP.COM
hdfs.kerberos.datanodePrincipal= dn/ytddata0.localdomain@HADOOP.COM
hdfs.kerberos.loginUser= hdfs-ytddata@HADOOP.COM
hdfs.kerberos.path=/etc/security/keytabs/hdfs.headless.keytab





#活动平台：行为日志
mq.validation.server.port=5672
mq.validation.server.host=10.0.1.30
mq.validation.server.username=admin
mq.validation.server.password=mRQTwfZOjQIYXIHY
mq.validation.server.vhost=/data
mq.validation.server.queueName=act.validation.log4data

#活动平台：用户旅程
mq.customerjourney.server.port=5672
mq.customerjourney.server.host=10.0.1.30
mq.customerjourney.server.username=admin
mq.customerjourney.server.password=mRQTwfZOjQIYXIHY
mq.customerjourney.server.vhost=/data
mq.customerjourney.server.queueName=act.data.send.event4data

#活动平台：用户旅程 demo测试
#mq.customerjourney.server.port=5672
#mq.customerjourney.server.host=10.0.1.2
#mq.customerjourney.server.username=admin
#mq.customerjourney.server.password=dasdIJD89q3wf6^@83e
#mq.customerjourney.server.vhost=/
#mq.customerjourney.server.queueName=test_event4_data


#demo环境 事件库
mq.event.server.host=10.0.1.2
mq.event.server.port=5672
mq.event.server.username=admin
mq.event.server.password=dasdIJD89q3wf6^@83e
mq.event.server.vhost=/
mq.event.source.server.queueName=event_source_data
mq.event.sink.server.queueName=event_sink_data_demo

event4flinkdata.queueName=event4_flink_data

#mq.validation.server.host=10.0.1.2
#mq.validation.server.username=admin
#mq.validation.server.password=dasdIJD89q3wf6^@83e
#mq.validation.server.vhost=/
#mq.validation.server.queueName=mq_56_act.validation.log4data
#


#mq.validation.server.host=192.168.2.131
#mq.validation.server.username=root
#mq.validation.server.password=root
#mq.validation.server.vhost=/
#mq.validation.server.queueName=act.data.send.event4data


hive.version=3.1.0
hive.catalogName=myhive
hive.defaultDatabase=act_data
hive.hiveConfDir=hdfs://ytddatademo.localdomain:8020/applications/flink/flink-libs/conf/

