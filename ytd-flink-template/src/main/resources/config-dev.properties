
hdfs.host=ytddata0
hdfs.port=8020
hdfs.username=hdfs
hdfs.password=hdfs
hdfs.rootpath=/di/

hdfs.kerberos.flag= false
hdfs.kerberos.conf= /etc/krb5.conf
hdfs.kerberos.realm= HADOOP.COM
hdfs.kerberos.kdc= 192.168.2.131
hdfs.kerberos.nameNodeprincipal= nn/ytddata0.localdomain@HADOOP.COM
hdfs.kerberos.datanodePrincipal= dn/ytddata0.localdomain@HADOOP.COM
hdfs.kerberos.loginUser= hdfs-ytddata@HADOOP.COM
hdfs.kerberos.path=/etc/security/keytabs/hdfs.headless.keytab

#校验数据mq
mq.validation.server.port=5672
mq.validation.server.host=10.0.1.30
mq.validation.server.username=admin
mq.validation.server.password=mRQTwfZOjQIYXIHY
mq.validation.server.vhost=/data
mq.validation.server.queueName=act.validation.log4data

mq.customerjourney.server.port=5672
mq.customerjourney.server.host=192.168.2.131
mq.customerjourney.server.username=root
mq.customerjourney.server.password=root
mq.customerjourney.server.vhost=/event
mq.customerjourney.server.queueName=event_source_data
mq.customerjourney.source.server.queueNames =test02,test01

#用户旅程数据拆分
mq.event.source.server.host=192.168.2.131
mq.event.source.server.port=5672
mq.event.source.server.username=root
mq.event.source.server.password=root
mq.event.source.server.vhost=/event
mq.event.source.server.queueNames=event_source_gm_data,event_hive_source_data
mq.event.source.exchange=event_source_exchange
mq.event.source.exchange.routingkey=eventRoutingKey
#事件库
mq.event.source.server.hive.queueName = event_hive_source_data


es.hosts=http://192.168.110.131:9200
es.index=user-event-log-lite-{useragent}
es.document.type=_doc
es.user.event.queueName=user-event



hive.version=3.1.0
hive.catalogName=myhive
hive.defaultDatabase=act_data
#hive.hiveConfDir=hdfs://ytddata00.localdomain:8020/applications/flink/flink-libs/conf/
hive.hiveConfDir=hdfs://ytddata0.localdomain:8020/applications/flink/flink-libs/conf/

